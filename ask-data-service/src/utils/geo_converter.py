"""
åœ°ç†æ•°æ®è½¬æ¢å·¥å…·

æä¾›SHPæ–‡ä»¶åˆ°CSVæ–‡ä»¶çš„è½¬æ¢åŠŸèƒ½ï¼Œæå–éç©ºé—´å±æ€§æ•°æ®ç”¨äºæ•°æ®é—®ç­”
"""

import os
import pandas as pd
import geopandas as gpd
from typing import Optional, Dict, Any, List
from .logger import get_logger, LogContext

logger = get_logger(__name__)

class GeoConverter:
    """åœ°ç†æ•°æ®è½¬æ¢å™¨"""
    
    @staticmethod
    def shp_to_csv(shp_file_path: str, output_csv_path: str = None, 
                   include_geometry_info: bool = True, 
                   geometry_columns: List[str] = None) -> str:
        """
        å°†SHPæ–‡ä»¶è½¬æ¢ä¸ºCSVæ–‡ä»¶
        
        Args:
            shp_file_path: SHPæ–‡ä»¶è·¯å¾„
            output_csv_path: è¾“å‡ºCSVæ–‡ä»¶è·¯å¾„ï¼Œå¦‚æœä¸ºNoneåˆ™è‡ªåŠ¨ç”Ÿæˆ
            include_geometry_info: æ˜¯å¦åŒ…å«å‡ ä½•ä¿¡æ¯ï¼ˆå¦‚åæ ‡ã€é¢ç§¯ç­‰ï¼‰
            geometry_columns: è¦æå–çš„å‡ ä½•ä¿¡æ¯åˆ—ååˆ—è¡¨
            
        Returns:
            str: è¾“å‡ºCSVæ–‡ä»¶è·¯å¾„
        """
        with LogContext(logger, f"è½¬æ¢SHPæ–‡ä»¶: {os.path.basename(shp_file_path)}"):
            try:
                # è¯»å–SHPæ–‡ä»¶
                gdf = gpd.read_file(shp_file_path, encoding='utf-8')
                logger.info(f"ğŸ“Š è¯»å–SHPæ–‡ä»¶æˆåŠŸ: {len(gdf)} ä¸ªè¦ç´ , {len(gdf.columns)} ä¸ªå­—æ®µ")
                
                # åˆ›å»ºDataFrameå‰¯æœ¬ç”¨äºè½¬æ¢
                df = gdf.copy()
                
                # å¤„ç†å‡ ä½•ä¿¡æ¯
                if include_geometry_info and 'geometry' in df.columns:
                    df = GeoConverter._extract_geometry_info(df, geometry_columns)
                
                # ç§»é™¤geometryåˆ—ï¼ˆå› ä¸ºCSVä¸æ”¯æŒå‡ ä½•å¯¹è±¡ï¼‰
                if 'geometry' in df.columns:
                    df = df.drop(columns=['geometry'])
                    logger.info("âœ‚ï¸ å·²ç§»é™¤geometryåˆ—")
                
                # å¤„ç†æ•°æ®ç±»å‹
                df = GeoConverter._clean_dataframe(df)
                
                # ç”Ÿæˆè¾“å‡ºè·¯å¾„
                if output_csv_path is None:
                    base_name = os.path.splitext(os.path.basename(shp_file_path))[0]
                    output_dir = os.path.dirname(shp_file_path)
                    output_csv_path = os.path.join(output_dir, f"{base_name}_converted.csv")
                
                # ä¿å­˜ä¸ºCSV
                df.to_csv(output_csv_path, index=False, encoding='utf-8-sig')
                logger.info(f"ğŸ’¾ CSVæ–‡ä»¶ä¿å­˜æˆåŠŸ: {output_csv_path}")
                logger.info(f"ğŸ“‹ è¾“å‡ºæ•°æ®: {len(df)} è¡Œ, {len(df.columns)} åˆ—")
                
                return output_csv_path
                
            except Exception as e:
                logger.error(f"âŒ SHPè½¬CSVå¤±è´¥: {str(e)}")
                raise
    
    @staticmethod
    def _extract_geometry_info(df: gpd.GeoDataFrame, geometry_columns: List[str] = None) -> pd.DataFrame:
        """
        ä»å‡ ä½•å¯¹è±¡ä¸­æå–æœ‰ç”¨çš„ä¿¡æ¯
        
        Args:
            df: åŒ…å«å‡ ä½•ä¿¡æ¯çš„GeoDataFrame
            geometry_columns: è¦æå–çš„å‡ ä½•ä¿¡æ¯åˆ—å
            
        Returns:
            pd.DataFrame: æ·»åŠ äº†å‡ ä½•ä¿¡æ¯çš„DataFrame
        """
        logger.info("ğŸ” æå–å‡ ä½•ä¿¡æ¯...")
        
        try:
            # é»˜è®¤è¦æå–çš„å‡ ä½•ä¿¡æ¯
            default_columns = ['centroid_x', 'centroid_y', 'area', 'perimeter', 'bounds']
            columns_to_extract = geometry_columns or default_columns
            
            geometry = df.geometry
            
            # æå–è´¨å¿ƒåæ ‡
            if 'centroid_x' in columns_to_extract or 'centroid_y' in columns_to_extract:
                centroids = geometry.centroid
                if 'centroid_x' in columns_to_extract:
                    df['centroid_x'] = centroids.x
                if 'centroid_y' in columns_to_extract:
                    df['centroid_y'] = centroids.y
                logger.debug("âœ… å·²æå–è´¨å¿ƒåæ ‡")
            
            # æå–é¢ç§¯ï¼ˆä»…å¯¹é¢è¦ç´ æœ‰æ•ˆï¼‰
            if 'area' in columns_to_extract:
                try:
                    # ç¡®ä¿ä½¿ç”¨æŠ•å½±åæ ‡ç³»è®¡ç®—é¢ç§¯
                    if df.crs and df.crs.is_geographic:
                        # å¦‚æœæ˜¯åœ°ç†åæ ‡ç³»ï¼Œè½¬æ¢ä¸ºWeb MercatoræŠ•å½±
                        df_projected = df.to_crs('EPSG:3857')
                        df['area'] = df_projected.geometry.area
                        logger.debug("âœ… å·²æå–é¢ç§¯ï¼ˆä½¿ç”¨æŠ•å½±åæ ‡ç³»ï¼‰")
                    else:
                        df['area'] = geometry.area
                        logger.debug("âœ… å·²æå–é¢ç§¯")
                except Exception as e:
                    logger.warning(f"âš ï¸ æå–é¢ç§¯å¤±è´¥: {e}")
            
            # æå–å‘¨é•¿
            if 'perimeter' in columns_to_extract:
                try:
                    if df.crs and df.crs.is_geographic:
                        df_projected = df.to_crs('EPSG:3857')
                        df['perimeter'] = df_projected.geometry.length
                        logger.debug("âœ… å·²æå–å‘¨é•¿ï¼ˆä½¿ç”¨æŠ•å½±åæ ‡ç³»ï¼‰")
                    else:
                        df['perimeter'] = geometry.length
                        logger.debug("âœ… å·²æå–å‘¨é•¿")
                except Exception as e:
                    logger.warning(f"âš ï¸ æå–å‘¨é•¿å¤±è´¥: {e}")
            
            # æå–è¾¹ç•Œæ¡†
            if 'bounds' in columns_to_extract:
                try:
                    bounds = geometry.bounds
                    df['min_x'] = bounds['minx']
                    df['min_y'] = bounds['miny']
                    df['max_x'] = bounds['maxx']
                    df['max_y'] = bounds['maxy']
                    logger.debug("âœ… å·²æå–è¾¹ç•Œæ¡†")
                except Exception as e:
                    logger.warning(f"âš ï¸ æå–è¾¹ç•Œæ¡†å¤±è´¥: {e}")
            
            return df
            
        except Exception as e:
            logger.warning(f"âš ï¸ å‡ ä½•ä¿¡æ¯æå–å¤±è´¥: {e}")
            return df
    
    @staticmethod
    def _clean_dataframe(df: pd.DataFrame) -> pd.DataFrame:
        """
        æ¸…ç†DataFrameï¼Œå¤„ç†æ•°æ®ç±»å‹å’Œç‰¹æ®Šå€¼
        
        Args:
            df: è¦æ¸…ç†çš„DataFrame
            
        Returns:
            pd.DataFrame: æ¸…ç†åçš„DataFrame
        """
        logger.info("ğŸ§¹ æ¸…ç†æ•°æ®...")
        
        # å¤„ç†åˆ—åï¼ˆç§»é™¤ç‰¹æ®Šå­—ç¬¦ï¼‰
        df.columns = [col.replace(' ', '_').replace('-', '_').replace('.', '_') 
                     for col in df.columns]
        
        # å¤„ç†æ•°æ®ç±»å‹
        for col in df.columns:
            # å°è¯•è½¬æ¢ä¸ºæ•°å€¼ç±»å‹
            if df[col].dtype == 'object':
                # å°è¯•è½¬æ¢ä¸ºæ•°å€¼
                try:
                    pd.to_numeric(df[col], errors='raise')
                    df[col] = pd.to_numeric(df[col], errors='coerce')
                except:
                    # ä¿æŒä¸ºå­—ç¬¦ä¸²ï¼Œä½†å¤„ç†Noneå€¼
                    df[col] = df[col].astype(str).replace('None', '')
        
        # å¤„ç†æ— ç©·å¤§å’ŒNaNå€¼
        df = df.replace([float('inf'), float('-inf')], None)
        
        logger.info("âœ… æ•°æ®æ¸…ç†å®Œæˆ")
        return df
    
    @staticmethod
    def get_shp_info(shp_file_path: str) -> Dict[str, Any]:
        """
        è·å–SHPæ–‡ä»¶çš„åŸºæœ¬ä¿¡æ¯
        
        Args:
            shp_file_path: SHPæ–‡ä»¶è·¯å¾„
            
        Returns:
            Dict: SHPæ–‡ä»¶ä¿¡æ¯
        """
        try:
            gdf = gpd.read_file(shp_file_path)
            
            info = {
                'features_count': len(gdf),
                'columns_count': len(gdf.columns),
                'columns': list(gdf.columns),
                'crs': str(gdf.crs) if gdf.crs else None,
                'geometry_type': gdf.geometry.geom_type.unique().tolist(),
                'bounds': gdf.total_bounds.tolist() if len(gdf) > 0 else None,
                'non_geometry_columns': [col for col in gdf.columns if col != 'geometry']
            }
            
            logger.info(f"ğŸ“‹ SHPæ–‡ä»¶ä¿¡æ¯: {info['features_count']} ä¸ªè¦ç´ , {info['columns_count']} ä¸ªå­—æ®µ")
            return info
            
        except Exception as e:
            logger.error(f"âŒ è·å–SHPæ–‡ä»¶ä¿¡æ¯å¤±è´¥: {str(e)}")
            raise
    
    @staticmethod
    def validate_shp_file(shp_file_path: str) -> bool:
        """
        éªŒè¯SHPæ–‡ä»¶æ˜¯å¦æœ‰æ•ˆ
        
        Args:
            shp_file_path: SHPæ–‡ä»¶è·¯å¾„
            
        Returns:
            bool: æ˜¯å¦æœ‰æ•ˆ
        """
        try:
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if not os.path.exists(shp_file_path):
                logger.error(f"âŒ SHPæ–‡ä»¶ä¸å­˜åœ¨: {shp_file_path}")
                return False
            
            # æ£€æŸ¥ç›¸å…³æ–‡ä»¶æ˜¯å¦å­˜åœ¨ï¼ˆ.shx, .dbfï¼‰
            base_path = os.path.splitext(shp_file_path)[0]
            required_files = ['.shx', '.dbf']
            
            for ext in required_files:
                file_path = base_path + ext
                if not os.path.exists(file_path):
                    logger.warning(f"âš ï¸ ç¼ºå°‘æ–‡ä»¶: {file_path}")
            
            # å°è¯•è¯»å–æ–‡ä»¶
            gdf = gpd.read_file(shp_file_path)
            
            if len(gdf) == 0:
                logger.warning("âš ï¸ SHPæ–‡ä»¶ä¸ºç©º")
                return False
            
            logger.info(f"âœ… SHPæ–‡ä»¶éªŒè¯é€šè¿‡: {len(gdf)} ä¸ªè¦ç´ ")
            return True
            
        except Exception as e:
            logger.error(f"âŒ SHPæ–‡ä»¶éªŒè¯å¤±è´¥: {str(e)}")
            return False 