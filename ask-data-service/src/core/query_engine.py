"""
æŸ¥è¯¢å¼•æ“æ¨¡å—

æä¾›æ™ºèƒ½æŸ¥è¯¢åŠŸèƒ½
"""

import os
import pandasai as pai
from .data_analyzer import DataAnalyzer
from ..utils.chart_patch import apply_chart_patch
from ..utils.string_response_patch import apply_string_response_patch
from ..utils.schema_database import SchemaDatabase
from ..utils.logger import get_logger, LogContext

# é…ç½®matplotlibä¸æ˜¾ç¤ºå¼¹çª—
import matplotlib
matplotlib.use('Agg')  # ä½¿ç”¨éäº¤äº’å¼åç«¯ï¼Œä¸æ˜¾ç¤ºå›¾è¡¨çª—å£
import matplotlib.pyplot as plt
plt.ioff()  # å…³é—­äº¤äº’æ¨¡å¼

# æŠ‘åˆ¶matplotlibçš„å„ç§è­¦å‘Š
import warnings
warnings.filterwarnings('ignore', category=UserWarning, module='matplotlib')
warnings.filterwarnings('ignore', message='.*Using categorical units to plot a list of strings.*')
warnings.filterwarnings('ignore', message='.*tight_layout.*')

# è®¾ç½®matplotlibæ—¥å¿—çº§åˆ«
import logging
logging.getLogger('matplotlib').setLevel(logging.ERROR)

class QueryEngine:
    """æ™ºèƒ½æŸ¥è¯¢å¼•æ“"""
    
    def __init__(self, llm, data_path=None, dataframe=None, use_semantic_layer=True, 
                 settings=None, dataset_id=None, schema_config=None, db=None):
        """
        åˆå§‹åŒ–æŸ¥è¯¢å¼•æ“
        
        Args:
            llm: è¯­è¨€æ¨¡å‹å®ä¾‹
            data_path: æ•°æ®æ–‡ä»¶è·¯å¾„
            dataframe: å·²åŠ è½½çš„DataFrame
            use_semantic_layer: æ˜¯å¦ä½¿ç”¨è¯­ä¹‰å±‚
            settings: ç³»ç»Ÿé…ç½®å¯¹è±¡
            dataset_id: æ•°æ®é›†ID
            schema_config: é¢„åŠ è½½çš„schemaé…ç½®
            db: å¯é€‰çš„æ•°æ®åº“è¿æ¥å®ä¾‹ï¼Œç”¨äºå¤ç”¨è¿æ¥
        """
        self.logger = get_logger(__name__)
        self.llm = llm
        self.analyzer = DataAnalyzer()
        self.use_semantic_layer = use_semantic_layer
        self.data_path = data_path
        self.settings = settings
        self.dataset_id = dataset_id
        self.schema_config = schema_config
        self.db = db  # ä¿å­˜æ•°æ®åº“è¿æ¥å¼•ç”¨
        
        # é…ç½®PandasAIè¯¦ç»†æ—¥å¿—
        self._configure_pandasai_logging()
        
        # é…ç½®PandasAI
        pai.config.set({
            "llm": llm,
            "verbose": True,
            "enable_cache": True,
            "cache_path": "cache",
            "custom_whitelisted_dependencies": ["matplotlib", "seaborn", "plotly", "kaleido"],
            "enforce_privacy": False,  # å…è®¸è®°å½•è¯¦ç»†æ—¥å¿—
            "log_server_url": None,   # ç¦ç”¨è¿œç¨‹æ—¥å¿—æœåŠ¡å™¨
            "advanced_reasoning": True  # å¯ç”¨é«˜çº§æ¨ç†æ—¥å¿—
        })
        
        # åŠ è½½æ•°æ®
        if use_semantic_layer and data_path:
            self.logger.info("ğŸ¯ å¯ç”¨è¯­ä¹‰å±‚æ¨¡å¼")
            
            # å¦‚æœæœ‰dataset_idï¼Œä½¿ç”¨æ•°æ®åº“ä¸­çš„é…ç½®
            if dataset_id:
                self.logger.info(f"âœ… ä½¿ç”¨æ•°æ®åº“é…ç½®: {dataset_id}")
                # ä½¿ç”¨å¢å¼ºçš„è¯­ä¹‰DataFrameåˆ›å»ºæ–¹æ³•ï¼ˆåŒ…å«transformationsæ”¯æŒï¼‰
                self.df = self.analyzer.create_enhanced_semantic_dataframe(data_path, dataset_id, self.db)
            else:
                self.logger.info("ğŸ“‹ è‡ªåŠ¨ç”Ÿæˆschemaé…ç½®")
                self.df = self.analyzer.create_semantic_dataframe(data_path)
        else:
            # ä¼ ç»Ÿæ¨¡å¼
            self.logger.info("ğŸ“Š ä½¿ç”¨ä¼ ç»Ÿæ¨¡å¼")
            if dataframe is not None:
                self.df = pai.DataFrame(dataframe)
            elif data_path:
                raw_df = self.analyzer.load_data(data_path)
                self.df = pai.DataFrame(raw_df)
            else:
                raise ValueError("å¿…é¡»æä¾›data_pathæˆ–dataframeå‚æ•°")
        
        # åˆ†ææ•°æ®ç»“æ„
        self.data_info = self.analyzer.analyze_structure(self.df)
        
        # åˆå§‹åŒ– query_id
        self.current_query_id = None
        
        # åº”ç”¨å›¾è¡¨æ–‡ä»¶åä¿®è¡¥
        apply_chart_patch()
        
        # åº”ç”¨Stringå“åº”è¡¥ä¸
        apply_string_response_patch()
    
    def _configure_pandasai_logging(self):
        """é…ç½®PandasAIè¯¦ç»†æ—¥å¿—"""
        import logging
        
        # è·å–PandasAIç›¸å…³çš„logger
        pandasai_loggers = [
            'pandasai',
            'pandasai.agent',
            'pandasai.smart_dataframe',
            'pandasai.helpers.query_exec_tracker',
            'pandasai.helpers.logger',
            'pandasai.pipelines',
            'pandasai.skills',
            'pandasai.smart_lake'
        ]
        
        # ä¸ºæ¯ä¸ªPandasAI loggerè®¾ç½®DEBUGçº§åˆ«
        for logger_name in pandasai_loggers:
            logger = logging.getLogger(logger_name)
            logger.setLevel(logging.DEBUG)
            
            # å¦‚æœæ²¡æœ‰handlerï¼Œæ·»åŠ æ–‡ä»¶handler
            if not logger.handlers:
                file_handler = logging.FileHandler('pandasai.log', encoding='utf-8')
                file_handler.setLevel(logging.DEBUG)
                
                # è®¾ç½®è¯¦ç»†çš„æ—¥å¿—æ ¼å¼
                formatter = logging.Formatter(
                    '%(asctime)s [%(levelname)s] %(name)s: %(message)s',
                    datefmt='%Y-%m-%d %H:%M:%S'
                )
                file_handler.setFormatter(formatter)
                
                logger.addHandler(file_handler)
                # é˜²æ­¢é‡å¤æ—¥å¿—
                logger.propagate = False
        
        self.logger.info("ğŸ”§ å·²é…ç½®PandasAIè¯¦ç»†æ—¥å¿—è¾“å‡ºåˆ° pandasai.log")
    
    def set_query_id(self, query_id):
        """
        è®¾ç½®å½“å‰æŸ¥è¯¢çš„IDï¼Œç”¨äºç”Ÿæˆå›¾è¡¨æ–‡ä»¶å
        
        Args:
            query_id: æŸ¥è¯¢ID
        """
        self.current_query_id = query_id
        # è®¾ç½®ç¯å¢ƒå˜é‡ï¼Œè®© PandasAI å¯ä»¥è®¿é—®åˆ° query_id
        os.environ['CURRENT_QUERY_ID'] = query_id
        
    def query(self, question, query_id=None):
        """
        æ‰§è¡Œæ™ºèƒ½æŸ¥è¯¢
        
        Args:
            question: ç”¨æˆ·é—®é¢˜
            query_id: æŸ¥è¯¢IDï¼Œç”¨äºç”Ÿæˆå›¾è¡¨æ–‡ä»¶å
            
        Returns:
            æŸ¥è¯¢ç»“æœ
        """
        # å¦‚æœæä¾›äº† query_idï¼Œåˆ™è®¾ç½®å®ƒ
        if query_id:
            self.set_query_id(query_id)
        # ç”Ÿæˆå¢å¼ºçš„æŸ¥è¯¢ä¸Šä¸‹æ–‡
        context = self.analyzer.generate_context(self.data_info)
        
        # æ„å»ºå®Œæ•´çš„æŸ¥è¯¢æŒ‡ä»¤
        enhanced_query = f"""è¯·ç”¨ä¸­æ–‡å›ç­”ä»¥ä¸‹é—®é¢˜ï¼Œä¸€å®šè¦ç»™å‡ºæ–‡æœ¬ç»“æœï¼Œé‡Œé¢æœ‰ä½ å¯¹é—®é¢˜çš„æ€»ç»“ï¼Œå¹¶æ ¹æ®ç»“æœç”Ÿæˆå›¾è¡¨ï¼š{question}

{context}

é‡è¦è¯´æ˜ï¼š
- ç»“æœæ ¼å¼ï¼šresult = {{"type": "string", "value": å…·ä½“å€¼}}
- å¦‚æœæ˜¯æ–‡æœ¬æè¿°ï¼Œä½¿ç”¨"string"ç±»å‹
"""
        
        try:
            # è®°å½•æŸ¥è¯¢å¼€å§‹
            self.logger.info(f"ğŸ” å¼€å§‹æŸ¥è¯¢: {question}")
            self.logger.debug(f"ğŸ“ å¢å¼ºæŸ¥è¯¢: {enhanced_query}")
            
            with LogContext(self.logger, "æ‰§è¡ŒPandasAIæŸ¥è¯¢"):
                # ç¡®ä¿PandasAIæ—¥å¿—è®°å½•åˆ°æ–‡ä»¶
                import logging
                logging.getLogger('pandasai').info(f"å¼€å§‹å¤„ç†æŸ¥è¯¢: {question}")
                
                response = self.df.chat(enhanced_query)
                
                # è®°å½•å“åº”ç±»å‹å’Œå†…å®¹
                self.logger.debug(f"ğŸ“Š å“åº”ç±»å‹: {type(response)}")
                self.logger.debug(f"ğŸ“‹ å“åº”å†…å®¹: {str(response)[:200]}...")
            
            # æ£€æŸ¥å“åº”æ˜¯å¦æœ‰æ•ˆï¼ˆé’ˆå¯¹Stringå“åº”è¡¥ä¸åçš„é€»è¾‘ï¼‰
            if self._is_valid_response(response):
                self.logger.info("âœ… æŸ¥è¯¢å®Œæˆ")
                # è®°å½•åˆ°PandasAIæ—¥å¿—
                logging.getLogger('pandasai').info(f"æŸ¥è¯¢æˆåŠŸå®Œæˆ: {question}")
                return response
            else:
                self.logger.warning("æŸ¥è¯¢æ²¡æœ‰è¿”å›æœ‰æ•ˆç»“æœ")
                logging.getLogger('pandasai').warning(f"æŸ¥è¯¢æ— ç»“æœ: {question}")
                # ç”±äºåº”ç”¨äº†Stringè¡¥ä¸ï¼Œè¿”å›é”™è¯¯ä¿¡æ¯å­—ç¬¦ä¸²
                return "æŸ¥è¯¢æ²¡æœ‰è¿”å›æœ‰æ•ˆç»“æœï¼Œè¯·å°è¯•é‡æ–°è¡¨è¿°é—®é¢˜"
                
        except Exception as e:
            self.logger.error(f"âŒ æŸ¥è¯¢å¤±è´¥ï¼š{str(e)}", exc_info=True)
            # è®°å½•åˆ°PandasAIæ—¥å¿—
            logging.getLogger('pandasai').error(f"æŸ¥è¯¢å¤±è´¥: {question} - é”™è¯¯: {str(e)}")
            # ç”±äºåº”ç”¨äº†Stringè¡¥ä¸ï¼Œè¿”å›é”™è¯¯ä¿¡æ¯å­—ç¬¦ä¸²
            return f"æŸ¥è¯¢è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯ï¼š{str(e)}\nğŸ’¡ å»ºè®®ï¼šå°è¯•é‡æ–°è¡¨è¿°é—®é¢˜æˆ–æ£€æŸ¥é—®é¢˜æ˜¯å¦ä¸æ•°æ®ç›¸å…³"
    
    def _is_valid_response(self, response):
        """
        æ£€æŸ¥å“åº”æ˜¯å¦æœ‰æ•ˆï¼ˆå®‰å…¨å¤„ç†Stringç±»å‹ï¼‰
        
        Args:
            response: æŸ¥è¯¢å“åº”
            
        Returns:
            bool: å“åº”æ˜¯å¦æœ‰æ•ˆ
        """
        if response is None:
            return False
        
        # ç°åœ¨ä¸»è¦å¤„ç†å­—ç¬¦ä¸²å“åº”
        if isinstance(response, str):
            return bool(response.strip())
        
        # å¦‚æœæ˜¯å…¶ä»–ç±»å‹ï¼Œä½¿ç”¨åŸæ¥çš„é€»è¾‘
        try:
            return bool(response) and str(response).strip()
        except (ValueError, TypeError):
            # å¦‚æœå‡ºç°ä»»ä½•è½¬æ¢é”™è¯¯ï¼Œè®¤ä¸ºå“åº”æœ‰æ•ˆ
            return True
    
    def get_data_info(self):
        """è·å–æ•°æ®ä¿¡æ¯"""
        return self.data_info
    
    def print_data_summary(self):
        """æ‰“å°æ•°æ®æ‘˜è¦ä¿¡æ¯"""
        print(f"ğŸ“Š æ•°æ®è§„æ¨¡ï¼š{self.data_info['shape'][0]}è¡Œ x {self.data_info['shape'][1]}åˆ—")
        
        if self.data_info['date_columns']:
            for col in self.data_info['date_columns']:
                range_key = col + '_range'
                if range_key in self.data_info:
                    print(f"ğŸ“… {col}ï¼š{self.data_info[range_key]}")
        
        print(f"ğŸ·ï¸ åˆ†ç±»å­—æ®µï¼š{len(self.data_info['categorical_info'])}ä¸ª")
        for col, info in self.data_info['categorical_info'].items():
            if isinstance(info, list) and len(info) <= 5:
                print(f"   {col}: {', '.join(map(str, info))}")
            else:
                print(f"   {col}: {info}")
    
    def print_detailed_info(self):
        """æ‰“å°è¯¦ç»†æ•°æ®ä¿¡æ¯"""
        print("\nğŸ“Š æ•°æ®è¯¦ç»†ä¿¡æ¯:")
        print(f"   è§„æ¨¡: {self.data_info['shape'][0]}è¡Œ x {self.data_info['shape'][1]}åˆ—")
        print(f"   åˆ—å: {', '.join(self.data_info['columns'])}")
        
        if self.data_info['date_columns']:
            for col in self.data_info['date_columns']:
                range_key = col + '_range'
                if range_key in self.data_info:
                    print(f"   {col}: {self.data_info[range_key]}")
        
        print("\nğŸ·ï¸ åˆ†ç±»å­—æ®µä¿¡æ¯:")
        for col, info in self.data_info['categorical_info'].items():
            if isinstance(info, list):
                print(f"   {col}: {', '.join(map(str, info))}")
            else:
                print(f"   {col}: {info}") 