"""
æŸ¥è¯¢å¼•æ“æ¨¡å—

æä¾›æ™ºèƒ½æŸ¥è¯¢åŠŸèƒ½
"""

import os
import pandasai as pai
from .data_analyzer import DataAnalyzer
from ..utils.chart_patch import apply_chart_patch
from ..utils.string_response_patch import apply_string_response_patch
from ..utils.schema_database import SchemaDatabase
from ..utils.logger import get_logger, LogContext
from ..utils.sql_interceptor import get_sql_interceptor, start_sql_interception, stop_sql_interception, clear_current_query

# é…ç½®matplotlibä¸æ˜¾ç¤ºå¼¹çª—
import matplotlib
matplotlib.use('Agg')  # ä½¿ç”¨éäº¤äº’å¼åç«¯ï¼Œä¸æ˜¾ç¤ºå›¾è¡¨çª—å£
import matplotlib.pyplot as plt
plt.ioff()  # å…³é—­äº¤äº’æ¨¡å¼

# æŠ‘åˆ¶matplotlibçš„å„ç§è­¦å‘Š
import warnings
warnings.filterwarnings('ignore', category=UserWarning, module='matplotlib')
warnings.filterwarnings('ignore', message='.*Using categorical units to plot a list of strings.*')
warnings.filterwarnings('ignore', message='.*tight_layout.*')

# è®¾ç½®matplotlibæ—¥å¿—çº§åˆ«
import logging
logging.getLogger('matplotlib').setLevel(logging.ERROR)

class QueryEngine:
    """æ™ºèƒ½æŸ¥è¯¢å¼•æ“"""
    
    def __init__(self, llm, data_path=None, dataframe=None, use_semantic_layer=True, 
                 settings=None, dataset_id=None, schema_config=None, db=None):
        """
        åˆå§‹åŒ–æŸ¥è¯¢å¼•æ“
        
        Args:
            llm: è¯­è¨€æ¨¡å‹å®ä¾‹
            data_path: æ•°æ®æ–‡ä»¶è·¯å¾„
            dataframe: å·²åŠ è½½çš„DataFrame
            use_semantic_layer: æ˜¯å¦ä½¿ç”¨è¯­ä¹‰å±‚
            settings: ç³»ç»Ÿé…ç½®å¯¹è±¡
            dataset_id: æ•°æ®é›†ID
            schema_config: é¢„åŠ è½½çš„schemaé…ç½®
            db: å¯é€‰çš„æ•°æ®åº“è¿æ¥å®ä¾‹ï¼Œç”¨äºå¤ç”¨è¿æ¥
        """
        self.logger = get_logger(__name__)
        self.llm = llm
        self.analyzer = DataAnalyzer()
        self.use_semantic_layer = use_semantic_layer
        self.data_path = data_path
        self.settings = settings
        self.dataset_id = dataset_id
        self.schema_config = schema_config
        self.db = db  # ä¿å­˜æ•°æ®åº“è¿æ¥å¼•ç”¨
        
        # é…ç½®PandasAIè¯¦ç»†æ—¥å¿—
        self._configure_pandasai_logging()
        
        # é…ç½®PandasAI
        pai.config.set({
            "llm": llm,
            "verbose": False,  # ç¦ç”¨æ§åˆ¶å°è¾“å‡ºï¼Œåªä½¿ç”¨æ–‡ä»¶æ—¥å¿—
            "enable_cache": True,
            "cache_path": "cache",
            "custom_whitelisted_dependencies": ["matplotlib", "seaborn", "plotly", "kaleido"],
            "enforce_privacy": False,  # å…è®¸è®°å½•è¯¦ç»†æ—¥å¿—
            "log_server_url": None,   # ç¦ç”¨è¿œç¨‹æ—¥å¿—æœåŠ¡å™¨
            "advanced_reasoning": True,  # å¯ç”¨é«˜çº§æ¨ç†æ—¥å¿—
            "save_logs": True,  # å¯ç”¨æ—¥å¿—ä¿å­˜
            "max_retries": 3,  # å¢åŠ é‡è¯•æ¬¡æ•°
            "retry_wait_time": 1,  # é‡è¯•ç­‰å¾…æ—¶é—´ï¼ˆç§’ï¼‰
            "enable_sql_query_validation": True  # å¯ç”¨SQLæŸ¥è¯¢éªŒè¯
        })
        
        # åŠ è½½æ•°æ®
        if use_semantic_layer and data_path:
            self.logger.info("ğŸ¯ å¯ç”¨è¯­ä¹‰å±‚æ¨¡å¼")
            
            # å¦‚æœæœ‰dataset_idï¼Œä½¿ç”¨æ•°æ®åº“ä¸­çš„é…ç½®
            if dataset_id:
                self.logger.info(f"âœ… ä½¿ç”¨æ•°æ®åº“é…ç½®: {dataset_id}")
                # ä½¿ç”¨å¢å¼ºçš„è¯­ä¹‰DataFrameåˆ›å»ºæ–¹æ³•ï¼ˆåŒ…å«transformationsæ”¯æŒï¼‰
                self.df = self.analyzer.create_enhanced_semantic_dataframe(data_path, dataset_id, self.db)
            else:
                self.logger.info("ğŸ“‹ è‡ªåŠ¨ç”Ÿæˆschemaé…ç½®")
                self.df = self.analyzer.create_semantic_dataframe(data_path)
        else:
            # ä¼ ç»Ÿæ¨¡å¼
            self.logger.info("ğŸ“Š ä½¿ç”¨ä¼ ç»Ÿæ¨¡å¼")
            if dataframe is not None:
                self.df = pai.DataFrame(dataframe)
            elif data_path:
                raw_df = self.analyzer.load_data(data_path)
                self.df = pai.DataFrame(raw_df)
            else:
                raise ValueError("å¿…é¡»æä¾›data_pathæˆ–dataframeå‚æ•°")
        
        # åˆ†ææ•°æ®ç»“æ„
        self.data_info = self.analyzer.analyze_structure(self.df)
        
        # åˆå§‹åŒ– query_id
        self.current_query_id = None
        
        # åº”ç”¨å›¾è¡¨æ–‡ä»¶åä¿®è¡¥
        apply_chart_patch()
        
        # åº”ç”¨Stringå“åº”è¡¥ä¸
        apply_string_response_patch()
        
        # åˆå§‹åŒ–SQLæ‹¦æˆªå™¨
        self.sql_interceptor = get_sql_interceptor()
    
    def _configure_pandasai_logging(self):
        """é…ç½®PandasAIè¯¦ç»†æ—¥å¿—"""
        import logging
        
        # ç¡®ä¿logsç›®å½•å­˜åœ¨
        logs_dir = 'logs'
        if not os.path.exists(logs_dir):
            os.makedirs(logs_dir)
            self.logger.info(f"ğŸ“ åˆ›å»ºæ—¥å¿—ç›®å½•: {logs_dir}")
        
        # PandasAIæ—¥å¿—æ–‡ä»¶è·¯å¾„
        pandasai_log_path = os.path.join(logs_dir, 'pandasai.log')
        
        # ä¿®è¡¥PandasAIå†…ç½®Loggerçš„æ—¥å¿—æ–‡ä»¶è·¯å¾„
        try:
            from pandasai.helpers.logger import Logger
            from pandasai.helpers.path import find_closest
            
            # ä¿å­˜åŸå§‹çš„find_closestå‡½æ•°
            original_find_closest = find_closest
            
            # åˆ›å»ºè‡ªå®šä¹‰çš„find_closestå‡½æ•°
            def custom_find_closest(filename):
                if filename == "pandasai.log":
                    return pandasai_log_path
                return original_find_closest(filename)
            
            # æ›¿æ¢find_closestå‡½æ•°
            import pandasai.helpers.path
            pandasai.helpers.path.find_closest = custom_find_closest
            
            # ä¹Ÿæ›¿æ¢loggeræ¨¡å—ä¸­çš„å¼•ç”¨
            import pandasai.helpers.logger
            pandasai.helpers.logger.find_closest = custom_find_closest
            
            self.logger.debug("ğŸ”§ å·²ä¿®è¡¥PandasAIå†…ç½®Loggerè·¯å¾„")
            
        except Exception as e:
            self.logger.warning(f"ä¿®è¡¥PandasAIæ—¥å¿—è·¯å¾„å¤±è´¥: {e}")
        
        # è·å–PandasAIç›¸å…³çš„logger
        pandasai_loggers = [
            'pandasai',
            'pandasai.agent',
            'pandasai.smart_dataframe',
            'pandasai.helpers.query_exec_tracker',
            'pandasai.helpers.logger',
            'pandasai.pipelines',
            'pandasai.skills',
            'pandasai.smart_lake'
        ]
        
        # ä¸ºæ¯ä¸ªPandasAI loggerè®¾ç½®DEBUGçº§åˆ«
        for logger_name in pandasai_loggers:
            logger = logging.getLogger(logger_name)
            logger.setLevel(logging.DEBUG)
            
            # æ¸…é™¤ç°æœ‰çš„handlers
            logger.handlers.clear()
            
            # æ·»åŠ æ–‡ä»¶handler
            file_handler = logging.FileHandler(pandasai_log_path, encoding='utf-8')
            file_handler.setLevel(logging.DEBUG)
            
            # è®¾ç½®è¯¦ç»†çš„æ—¥å¿—æ ¼å¼
            formatter = logging.Formatter(
                '%(asctime)s [%(levelname)s] %(name)s: %(message)s',
                datefmt='%Y-%m-%d %H:%M:%S'
            )
            file_handler.setFormatter(formatter)
            
            logger.addHandler(file_handler)
            # é˜²æ­¢é‡å¤æ—¥å¿—
            logger.propagate = False
        
        self.logger.info(f"ğŸ”§ å·²é…ç½®PandasAIè¯¦ç»†æ—¥å¿—è¾“å‡ºåˆ° {pandasai_log_path}")
    
    def set_query_id(self, query_id):
        """
        è®¾ç½®å½“å‰æŸ¥è¯¢çš„IDï¼Œç”¨äºç”Ÿæˆå›¾è¡¨æ–‡ä»¶å
        
        Args:
            query_id: æŸ¥è¯¢ID
        """
        self.current_query_id = query_id
        # è®¾ç½®ç¯å¢ƒå˜é‡ï¼Œè®© PandasAI å¯ä»¥è®¿é—®åˆ° query_id
        os.environ['CURRENT_QUERY_ID'] = query_id
        
    def query(self, question, query_id=None):
        """
        æ‰§è¡Œæ™ºèƒ½æŸ¥è¯¢
        
        Args:
            question: ç”¨æˆ·é—®é¢˜
            query_id: æŸ¥è¯¢IDï¼Œç”¨äºç”Ÿæˆå›¾è¡¨æ–‡ä»¶å
            
        Returns:
            æŸ¥è¯¢ç»“æœ
        """
        # å¦‚æœæä¾›äº† query_idï¼Œåˆ™è®¾ç½®å®ƒ
        if query_id:
            self.set_query_id(query_id)
        # ç”Ÿæˆå¢å¼ºçš„æŸ¥è¯¢ä¸Šä¸‹æ–‡
        context = self.analyzer.generate_context(self.data_info)
        
        # æ„å»ºå®Œæ•´çš„æŸ¥è¯¢æŒ‡ä»¤
        enhanced_query = f"""è¯·åˆ†æä»¥ä¸‹é—®é¢˜å¹¶ç”¨ä¸­æ–‡æ–‡æœ¬å½¢å¼å›ç­”ï¼š{question}

{context}

é‡è¦è¯´æ˜ï¼š
- å¿…é¡»ä½¿ç”¨execute_sql_queryå‡½æ•°æ‰§è¡ŒSQLæŸ¥è¯¢
- å¯¹äºé¢ç§¯ç±»æŸ¥è¯¢ï¼ˆå¦‚"æ—±åœ°é¢ç§¯"ï¼‰ï¼Œéœ€è¦é€šè¿‡æ¡ä»¶ç­›é€‰è®¡ç®—ï¼š
  ä¾‹å¦‚ï¼šSELECT SUM(TBMJ) FROM table_name WHERE åœ°ç±»åç§° = 'æ—±åœ°'
- å¯¹äºåœ°åŒºç­›é€‰ï¼Œä½¿ç”¨å¿çº§åç§°ã€å¸‚çº§åç§°ç­‰å­—æ®µ
- ä½¿ç”¨è¡¨æ ¼ä¸­å­˜åœ¨çš„åˆ—åï¼ŒåŒ…æ‹¬ä¸­æ–‡åˆ—åï¼ˆå¦‚"åœ°ç±»åç§°"ã€"å¿çº§åç§°"ç­‰ï¼‰
- é‡è¦ï¼šè¯·ä½¿ç”¨PandasAIæä¾›çš„å®é™…è¡¨å
- ä»£ç æ ¼å¼ç¤ºä¾‹ï¼š
```python
# æ‰§è¡ŒSQLæŸ¥è¯¢ï¼ˆä½¿ç”¨æ­£ç¡®çš„è¡¨åï¼‰
result = execute_sql_query("SELECT SUM(TBMJ) FROM table_name WHERE åœ°ç±»åç§° = 'æ—±åœ°' AND å¿çº§åç§° = 'å®‰è¿œå¿'")
# å¤„ç†ç»“æœå¹¶è¿”å›
final_result = {{"type": "string", "value": f"å®‰è¿œå¿æ—±åœ°é¢ç§¯ä¸ºï¼š{{result}}å¹³æ–¹ç±³"}}
```
- ç¡®ä¿ä»£ç å®Œæ•´ä¸”å¯æ‰§è¡Œ
- è¿”å›æ ¼å¼ï¼šresult = {{"type": "string", "value": "å…·ä½“ç­”æ¡ˆ"}}
"""
        
        try:
            # è®°å½•æŸ¥è¯¢å¼€å§‹
            self.logger.info(f"ğŸ” å¼€å§‹æŸ¥è¯¢: {question}")
            self.logger.debug(f"ğŸ“ å¢å¼ºæŸ¥è¯¢: {enhanced_query}")
            
            # æ¸…ç©ºä¹‹å‰çš„SQLè®°å½•å¹¶å¯åŠ¨æ‹¦æˆª
            clear_current_query()
            start_sql_interception()
            
            with LogContext(self.logger, "æ‰§è¡ŒPandasAIæŸ¥è¯¢"):
                # ç¡®ä¿PandasAIæ—¥å¿—è®°å½•åˆ°æ–‡ä»¶
                import logging
                logging.getLogger('pandasai').info(f"å¼€å§‹å¤„ç†æŸ¥è¯¢: {question}")
                
                # æ·»åŠ é‡è¯•æœºåˆ¶å’Œä»£ç éªŒè¯
                max_attempts = 3
                for attempt in range(max_attempts):
                    try:
                        response = self.df.chat(enhanced_query)
                        
                        # éªŒè¯å“åº”æ˜¯å¦æœ‰æ•ˆ
                        if self._is_valid_response(response):
                            break
                        elif attempt < max_attempts - 1:
                            self.logger.warning(f"ç¬¬{attempt + 1}æ¬¡æŸ¥è¯¢æ— æ•ˆå“åº”ï¼Œé‡è¯•...")
                            logging.getLogger('pandasai').warning(f"æŸ¥è¯¢é‡è¯• {attempt + 1}/{max_attempts}: {question}")
                            continue
                        else:
                            self.logger.error(f"æ‰€æœ‰{max_attempts}æ¬¡æŸ¥è¯¢å°è¯•å‡å¤±è´¥")
                            response = "æŸ¥è¯¢å¤±è´¥ï¼Œè¯·é‡æ–°è¡¨è¿°é—®é¢˜"
                            
                    except Exception as e:
                        if attempt < max_attempts - 1:
                            self.logger.warning(f"ç¬¬{attempt + 1}æ¬¡æŸ¥è¯¢å¼‚å¸¸ï¼Œé‡è¯•: {str(e)}")
                            logging.getLogger('pandasai').warning(f"æŸ¥è¯¢å¼‚å¸¸é‡è¯• {attempt + 1}/{max_attempts}: {question} - {str(e)}")
                            continue
                        else:
                            raise e
                
                # è®°å½•å“åº”ç±»å‹å’Œå†…å®¹
                self.logger.debug(f"ğŸ“Š å“åº”ç±»å‹: {type(response)}")
                self.logger.debug(f"ğŸ“‹ å“åº”å†…å®¹: {str(response)[:200]}...")
                
                # è®°å½•æ‰§è¡Œçš„SQL
                executed_sql = self.sql_interceptor.get_latest_sql()
                if executed_sql:
                    self.logger.info(f"ğŸ—‚ï¸ æ‰§è¡Œçš„SQLæŸ¥è¯¢: {executed_sql}")
                else:
                    self.logger.info("ğŸ“ æœªæ£€æµ‹åˆ°SQLæŸ¥è¯¢æ‰§è¡Œ")
            
            # æ£€æŸ¥å“åº”æ˜¯å¦æœ‰æ•ˆï¼ˆé’ˆå¯¹Stringå“åº”è¡¥ä¸åçš„é€»è¾‘ï¼‰
            if self._is_valid_response(response):
                self.logger.info("âœ… æŸ¥è¯¢å®Œæˆ")
                # è®°å½•åˆ°PandasAIæ—¥å¿—
                logging.getLogger('pandasai').info(f"æŸ¥è¯¢æˆåŠŸå®Œæˆ: {question}")
                return response
            else:
                self.logger.warning("æŸ¥è¯¢æ²¡æœ‰è¿”å›æœ‰æ•ˆç»“æœ")
                logging.getLogger('pandasai').warning(f"æŸ¥è¯¢æ— ç»“æœ: {question}")
                # ç”±äºåº”ç”¨äº†Stringè¡¥ä¸ï¼Œè¿”å›é”™è¯¯ä¿¡æ¯å­—ç¬¦ä¸²
                return "æŸ¥è¯¢æ²¡æœ‰è¿”å›æœ‰æ•ˆç»“æœï¼Œè¯·å°è¯•é‡æ–°è¡¨è¿°é—®é¢˜"
                
        except Exception as e:
            self.logger.error(f"âŒ æŸ¥è¯¢å¤±è´¥ï¼š{str(e)}", exc_info=True)
            # è®°å½•åˆ°PandasAIæ—¥å¿—
            logging.getLogger('pandasai').error(f"æŸ¥è¯¢å¤±è´¥: {question} - é”™è¯¯: {str(e)}")
            # ç”±äºåº”ç”¨äº†Stringè¡¥ä¸ï¼Œè¿”å›é”™è¯¯ä¿¡æ¯å­—ç¬¦ä¸²
            return f"æŸ¥è¯¢è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯ï¼š{str(e)}\nğŸ’¡ å»ºè®®ï¼šå°è¯•é‡æ–°è¡¨è¿°é—®é¢˜æˆ–æ£€æŸ¥é—®é¢˜æ˜¯å¦ä¸æ•°æ®ç›¸å…³"
        finally:
            # åœæ­¢SQLæ‹¦æˆª
            stop_sql_interception()
    
    def _is_valid_response(self, response):
        """
        æ£€æŸ¥å“åº”æ˜¯å¦æœ‰æ•ˆï¼ˆå®‰å…¨å¤„ç†Stringç±»å‹ï¼‰
        
        Args:
            response: æŸ¥è¯¢å“åº”
            
        Returns:
            bool: å“åº”æ˜¯å¦æœ‰æ•ˆ
        """
        if response is None:
            return False
        
        # ç°åœ¨ä¸»è¦å¤„ç†å­—ç¬¦ä¸²å“åº”
        if isinstance(response, str):
            return bool(response.strip())
        
        # å¦‚æœæ˜¯å…¶ä»–ç±»å‹ï¼Œä½¿ç”¨åŸæ¥çš„é€»è¾‘
        try:
            return bool(response) and str(response).strip()
        except (ValueError, TypeError):
            # å¦‚æœå‡ºç°ä»»ä½•è½¬æ¢é”™è¯¯ï¼Œè®¤ä¸ºå“åº”æœ‰æ•ˆ
            return True
    
    def get_data_info(self):
        """è·å–æ•°æ®ä¿¡æ¯"""
        return self.data_info
    
    def get_executed_sqls(self):
        """è·å–å½“å‰æŸ¥è¯¢æ‰§è¡Œçš„SQLæŸ¥è¯¢åˆ—è¡¨"""
        return self.sql_interceptor.get_current_query_sqls()
    
    def get_executed_sqls_string(self):
        """è·å–å½“å‰æŸ¥è¯¢æ‰§è¡Œçš„SQLæŸ¥è¯¢å­—ç¬¦ä¸²"""
        return self.sql_interceptor.get_latest_sql()
    
    def get_latest_sql(self):
        """è·å–æœ€æ–°æ‰§è¡Œçš„SQL"""
        return self.sql_interceptor.get_latest_sql()
    
    def print_data_summary(self):
        """æ‰“å°æ•°æ®æ‘˜è¦ä¿¡æ¯"""
        print(f"ğŸ“Š æ•°æ®è§„æ¨¡ï¼š{self.data_info['shape'][0]}è¡Œ x {self.data_info['shape'][1]}åˆ—")
        
        if self.data_info['date_columns']:
            for col in self.data_info['date_columns']:
                range_key = col + '_range'
                if range_key in self.data_info:
                    print(f"ğŸ“… {col}ï¼š{self.data_info[range_key]}")
        
        print(f"ğŸ·ï¸ åˆ†ç±»å­—æ®µï¼š{len(self.data_info['categorical_info'])}ä¸ª")
        for col, info in self.data_info['categorical_info'].items():
            if isinstance(info, list) and len(info) <= 5:
                print(f"   {col}: {', '.join(map(str, info))}")
            else:
                print(f"   {col}: {info}")
    
    def print_detailed_info(self):
        """æ‰“å°è¯¦ç»†æ•°æ®ä¿¡æ¯"""
        print("\nğŸ“Š æ•°æ®è¯¦ç»†ä¿¡æ¯:")
        print(f"   è§„æ¨¡: {self.data_info['shape'][0]}è¡Œ x {self.data_info['shape'][1]}åˆ—")
        print(f"   åˆ—å: {', '.join(self.data_info['columns'])}")
        
        if self.data_info['date_columns']:
            for col in self.data_info['date_columns']:
                range_key = col + '_range'
                if range_key in self.data_info:
                    print(f"   {col}: {self.data_info[range_key]}")
        
        print("\nğŸ·ï¸ åˆ†ç±»å­—æ®µä¿¡æ¯:")
        for col, info in self.data_info['categorical_info'].items():
            if isinstance(info, list):
                print(f"   {col}: {', '.join(map(str, info))}")
            else:
                print(f"   {col}: {info}") 